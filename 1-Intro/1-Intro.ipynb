{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5181b600-22a3-44c1-8516-454ff5361d37",
   "metadata": {},
   "source": [
    "# Notebook 1 : Prise en main de scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd19f49-8ede-4b4f-b0f0-2f4afc8a2e79",
   "metadata": {},
   "source": [
    "Notebook préparé par [Chloé-Agathe Azencott](http://cazencott.info).\n",
    "\n",
    "Ce notebook vous permettra de découvrir des fonctionalités de `scikit-learn` permettant :\n",
    "* d'entrainer et évaluer un algorithme d'apprentissage supervisé\n",
    "* d'encoder des variables qualitatives ;\n",
    "* de ramener des variables à une fourchette de valeurs ;\n",
    "* de transformer des variables pour rapprocher leur distribution de celle d'une gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2cfc6-5b12-4033-99af-32d91fb916c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger numpy as np, matplotlib as plt\n",
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595591ab-82f3-4ace-be7a-1e46ff15dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d6e9e-97fc-441d-9972-8cd94b57fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abe759-db4b-4d1b-8553-ad21693d0f10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Chargement des données\n",
    "Dans ce notebook nous allons travailler avec les données contenues dans le fichier `data/auto-mpg.tsv`. Ces données, obtenues sur https://archive.ics.uci.edu/ml/datasets/Auto+MPG, décrivent des voitures par les variables suivantes :\n",
    "\n",
    "    1. mpg:           consommation (en miles par gallon), continue\n",
    "    2. cylinders:     nombre de cylindres, discrète\n",
    "    3. displacement:  cylindrée, continue\n",
    "    4. horsepower:    chevaux-vapeur, continue\n",
    "    5. weight:        poids, continue\n",
    "    6. acceleration:  accélération, continue\n",
    "    7. model year:    année, discrète\n",
    "    8. origin:        région d'origine, discrète (1=Amérique du Nord ; 2=Europe ; 3=Asie)\n",
    "    9. car name:      nom, chaîne de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edcab5-7f5c-45c4-82f7-b12403ecd1bc",
   "metadata": {},
   "source": [
    "Notre but va être de prédire la consommation d'un véhicule à partir des autres variables (à l'exclusion du nom de la voiture, qui est un identifiant unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9f738-7cec-4de2-a915-79c8d4e1a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"data/auto-mpg.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad3627-1c2d-4852-9c8f-5b14f2322f23",
   "metadata": {},
   "source": [
    "__Alternativement :__ Si vous avez besoin de télécharger le fichier (par exemple sur colab) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63693f34-6955-4a87-b5c2-4dab5d4b7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/chagaz/cp-ia-intro-ml-2022/main/1-Intro/data/auto-mpg.tsv\n",
    "\n",
    "df = pd.read_csv(\"auto-mpg.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fb74c-c0b2-452a-944b-afece07d2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b48ad-6a5d-47a4-82c5-c875258d101a",
   "metadata": {},
   "source": [
    "### Création des matrices X et y de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1204456-d71f-46ea-a278-990616f1b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcee81-20f7-4c8c-8824-5dbe90bb330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97487328-a440-48c0-99a9-e065af55f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c435ce0-0dbe-43da-a04c-68f63bfdf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a03ccc-49dc-4ca8-92e6-22c8da67e75c",
   "metadata": {},
   "source": [
    "## 2. Visualisation des données\n",
    "\n",
    "Nous allons maintenant visualiser les variables représentant nos véhicules. Pour ce faire, nous allons séparer les variables continues (que nous allons représenter chacune par un histogramme) des variables discrètes (que nous allons représenter chacune par un diagramme en barre).\n",
    "\n",
    "N'hésitez pas à ajuster les paramètres des méthodes de `matplotlib` pour produire des graphiques plus lisibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c68086-454c-4351-a3ca-0dbbad09bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['displacement', 'horsepower', 'weight', 'acceleration']\n",
    "discrete_features = ['cylinders', 'model year', 'origin']\n",
    "\n",
    "features = list(df.drop(columns=['mpg', 'car name']).columns)\n",
    "\n",
    "continuous_features_idx = [features.index(feat_name) for feat_name in continuous_features]\n",
    "discrete_features_idx = [features.index(feat_name) for feat_name in discrete_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38294fa4-a582-4d16-99b8-58a77e00d005",
   "metadata": {},
   "source": [
    "### Histogrammes pour les variables continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e370009-03a2-43f6-9f0a-48c00799479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # créer un graphique à la position (plot_idx+1) d'une grille 2x2\n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    # afficher l'histogramme de la variable feat_idx\n",
    "    h = ax.hist(X[:, feat_idx], bins=30, edgecolor='none')\n",
    "    # utiliser le nom de la variable comme titre\n",
    "    ax.set_title(features[feat_idx])\n",
    "# espacement entre les graphiques\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33bb7d-4adb-41ea-965e-a8fbb7ccbd47",
   "metadata": {},
   "source": [
    "### Diagrammes en barres pour les variables discrètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cf31b-41c0-45b7-8b9d-e584a1a9457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # créer un graphique à la position (plot_idx+1) d'une grille 1x3\n",
    "    ax = fig.add_subplot(1, 3, (plot_idx+1))\n",
    "\n",
    "    feature_values = np.unique(X[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X[:, feat_idx]==value)[0]))/X.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    \n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=list([int(n) for n in feature_values]))\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre\n",
    "    ax.set_title(features[feat_idx])\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e59774-0daa-4daf-bd60-2030ee0601ca",
   "metadata": {},
   "source": [
    "__Question :__ Observez les ordres de grandeur / fourchettes de valeur des différentes variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af01391-f762-46bc-8d29-3aac38491aed",
   "metadata": {},
   "source": [
    "### Histogramme des étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e07275-29b3-4897-a32f-f6e6add0f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=30, edgecolor='none')\n",
    "plt.title('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3058f-a348-43f7-8c91-93adf9386449",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Régression linéaire\n",
    "\n",
    "Nous allons maintenant utiliser `scikit-learn` pour entraîner une régression linéaire sur les données.\n",
    "\n",
    "Les modèles linéaires de `scikit-learn` sont implémentés dans le module [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). __N'hésitez pas à vous référer fréquemment à la documentation de scikit-learn, qui est très complète.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f622a-0b03-4a45-9e7e-ab95d7f15504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846d765-f7d3-4c79-bcc4-981b94e0321d",
   "metadata": {},
   "source": [
    "### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9cb50b-f0f6-4825-81ae-5ba728edf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un objet LinearRegression\n",
    "predictor = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf936ccb-90ee-4d4e-b42b-8f90bfa2627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement de cet objet sur les données \n",
    "predictor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d712321-7238-46b7-a96c-49ec0a8d859e",
   "metadata": {},
   "source": [
    "### Prédictions\n",
    "Nous pouvons maintenant utiliser ce modèle pour _prédire_ des étiquettes à partir des variables. En particulier, on peut l'appliquer aux données que l'on vient d'utiliser pour l'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698720d4-a50b-40cc-8d38-3ddd65790c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d92256-6ea6-48df-aa98-322b48972bc5",
   "metadata": {},
   "source": [
    "__ATTENTION__ En pratique, ce qui nous intéresse vraiment est la capacité d'un modèle à faire de bonnes prédictions sur des données qui n'ont _pas_ été utilisées pour l'entraîner. La performance d'un modèle sur les données qui ont servi à l'entraîner ne permet pas de déterminer s'il s'agit d'un bon modèle. Nous en discuterons plus en détails dans la suite du cours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979615f-15de-4305-ba48-5b054d39dfb3",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Il s'agit maintenant d'évaluer ce modèle.\n",
    "\n",
    "Pour cela, nous allons utiliser les fonctionalités du module [https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics](`metrics`) de `scikit-learn`.\n",
    "\n",
    "Comme il s'agit d'un problème de régression, nous allons utiliser la __RMSE__ (_Root Mean Squared Error_) comme mesure de la performance du modèle : il s'agit de la racine carrée de la moyenne des carrés des erreurs. On utilise la racine carrée pour des questions d'homogénéité : la RMSE s'exprime dans la même unité que l'étiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb9ef8-2c93-4a3f-9eab-f433239fe583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f57e8a-36b0-4958-b4b1-fd7a409e1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: %.2f\" % metrics.mean_squared_error(y, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50245ac1-99ef-4a07-86d8-cf00a0ad73ad",
   "metadata": {},
   "source": [
    "Alternativement (selon version de scikit-learn) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30367f4e-415b-42ab-b358-577828f46055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bb5c7-ad01-420e-afaf-1dff475f80c3",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de cette erreur ? Est-elle faible? Grande ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e129ac5-b3f8-4fdc-a29e-a751c2a9bfd9",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70180a-2337-456b-a2ae-7712181123c4",
   "metadata": {},
   "source": [
    "Nous pouvons aussi utiliser une visualisation, et représenter chaque individu du jeu de test par son étiquette prédite vs. sa vraie étiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792df7b7-b5d4-448e-bb91-e261b14c4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y, y_pred)\n",
    "\n",
    "plt.xlabel(\"Consommation réelle (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y), np.min(y_pred)])-1\n",
    "axis_max = np.max([np.max(y), np.max(y_pred)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c81f85-f65c-443a-91f7-0f1d0ddb6093",
   "metadata": {},
   "source": [
    "### Coefficients de régression\n",
    "\n",
    "Pour comprendre notre modèle, nous pouvons regarder les coefficients affectés à chaque variable dans le modèle linéaire appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fccd1e-daa5-4fab-b753-2992692d9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour chaque variable, la valeur absolue de son coefficient dans le modèle\n",
    "num_features = X.shape[1]\n",
    "feature_names = df.drop(columns=['mpg', 'car name']).columns\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_))\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175ddab-b66f-444e-ac53-d9f331004c4d",
   "metadata": {},
   "source": [
    "__Question :__ Quelle variable a le plus fort coefficient (en valeur absolue) ? Pensez-vous que cela signifie que cette variable joue un rôle très important dans la prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1658799-4ce5-4d22-baa2-96a41352d1e1",
   "metadata": {},
   "source": [
    "## 4. Changement d'échelle des variables\n",
    "\n",
    "Le fait que les variables soient sur des échelles différentes rend l'interprétation des coefficients de la régression linéaire délicate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed9e59-843e-40be-872f-d4b6d767ba94",
   "metadata": {},
   "source": [
    "### Transformation des variables\n",
    "\n",
    "Centrer (ramener à une moyenne de 0) et réduire (ramener à un écart-type de 1) les variables permet de remédier à ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44524480-ea54-4932-b53a-9999ed555101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2df87-2de8-4979-adae-aafea5ddca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "standard_scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8da583-8c35-4e80-849d-becd9ef63d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = standard_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8a848-2273-4281-8dd2-587cba331b1a",
   "metadata": {},
   "source": [
    "### Visualisation des nouvelles variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd7735-74ea-4e29-9b5f-8320458e99fe",
   "metadata": {},
   "source": [
    "#### Histogrammes pour les variables continues\n",
    "On remplace ici `X` par `X_scaled` dans le code utilisé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4c46d-b5dd-4918-8a14-cdecebf45a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # créer un graphique à la position (plot_idx+1) d'une grille 2x2\n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    # afficher l'histogramme de la variable feat_idx\n",
    "    h = ax.hist(X_scaled[:, feat_idx], bins=30, edgecolor='none')\n",
    "    # utiliser le nom de la variable comme titre\n",
    "    ax.set_title(features[feat_idx])\n",
    "# espacement entre les graphiques\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddec0ad-8c63-4ac2-aedf-9923e04f8aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Diagrammes en barres pour les variables discrètes\n",
    "On remplace ici `X` par `X_scaled` dans le code utilisé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defa9d1-45d0-41f1-8a1f-87cdde1fc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # créer un graphique à la position (plot_idx+1) d'une grille 1x3\n",
    "    ax = fig.add_subplot(1, 3, (plot_idx+1))\n",
    "\n",
    "    feature_values = np.unique(X_scaled[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_scaled[:, feat_idx]==value)[0]))/X_scaled.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    \n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=list(['%.1f' % n for n in feature_values]))\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre\n",
    "    ax.set_title(features[feat_idx])\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b418d12-e822-4d67-a9a7-d8c308bbe82e",
   "metadata": {},
   "source": [
    "### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11642ea2-472f-4d19-ba19-5c556eb82107",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant entraîner un modèle `predictor_scaled` sur les données centrées-réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07401b-7b66-41a0-bdc7-8f703f8ea3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouvel objet LinearRegression \n",
    "predictor_scaled = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_dummy sur les nouvelles données\n",
    "predictor_scaled.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988b33f-2061-4d03-8539-d7e1ddaba147",
   "metadata": {},
   "source": [
    "Et créer un array `y_pred_scaled` qui contient les prédictions de `predictor_scaled` sur les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818952d-a55b-4b88-b94f-57342bd3e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = predictor_scaled.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5827c26-d047-49dc-a298-fd3bd8443221",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6924a-b7ab-4d16-b4af-9f81dd7a747e",
   "metadata": {},
   "source": [
    "La RMSE de ce nouveau modèle est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64363f-9d3b-4bf2-9188-077c66e53922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE (scaled): %.2f\" % metrics.mean_squared_error(y, y_pred_scaled, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b5d1c-9ef1-449f-83df-43439b77197d",
   "metadata": {},
   "source": [
    "__Question :__ La comparer à la RMSE précédente. Les prédictions sont-elles différentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed1443-cefa-4f19-b40b-ab14f8b163b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred_scaled, y_pred)\n",
    "\n",
    "plt.xlabel(\"Consommation prédite sur les données centrées-réduites (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y), np.min(y_pred)])-1\n",
    "axis_max = np.max([np.max(y), np.max(y_pred)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39402c2c-831e-4074-9eba-072445d26cfd",
   "metadata": {},
   "source": [
    "#### Comparaison des coefficients de régression.\n",
    "Enfin, nous pouvons comparer les coefficients de régression des deux modèles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc65bf5-c352-4dc0-a09e-a4f62d57dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour chaque variable, la valeur absolue de son coefficient dans le modèle\n",
    "num_features = X.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Originales')\n",
    "\n",
    "plt.scatter(range(num_features), np.abs(predictor_scaled.coef_), label='Centrées-réduites', marker='v')\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "plt.legend(loc=(0.02, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut noter que, même si la RMSE est la même, le fait de centrer-réduire les variables a changé la valeur des paramètres appris par le modèle. On peut comparer par exemple les valeurs prises par l'intercept (terme indépendant dans le modèle linéaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b5cd9-c3c4-4688-9b96-1b4f2d5a7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377fcb7-41b8-4842-a3b4-627058655803",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_scaled.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0263c88-816e-4830-9feb-4402a4e026de",
   "metadata": {},
   "source": [
    "__Question :__ Quelles sont maintenant les variables les plus pertinentes pour prédire la consommation d'un véhicule ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32606f-2a11-4652-adea-7161b6dcfaf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Encodage des variables qualitatives\n",
    "La variable `origin` est une variable qualitative : l'encodage 1-2-3 est tout à fait arbitraire. Il suppose en particulier, si on réfléchit en termes de distances, que l'Asie est deux fois plus loin de l'Amérique du Nord que de l'Europe, ce qui n'a aucun sens.\n",
    "\n",
    "Un encodage plus raisonnable pour ce genre de cas est ce qu'on appelle l'encodage _one-hot_, ou encore _dummy encoding_ : on représente la variable par autant de variables binaires qu'il y a de valeurs possibles (3 dans le cas de la variable `origin` : la première correspond à Amérique du Nord, la deuxième à Europe, la troisième à Asie), et on met à `1` la seule de ces variables binaires correspondant à la valeur que l'on encode.\n",
    "\n",
    "Ainsi l'unique variable `origin` devient 3 variables binaires:\n",
    "```    \n",
    "   Amérique du Nord --> 1, 0, 0\n",
    "   Europe --> 0, 1, 0\n",
    "   Asie --> 0, 0, 1\n",
    "```  \n",
    "Cette représentation a l'inconvénient d'augmenter le nombre de variables, mais les distances euclidiennes sont maintenant plus raisonnables (elles valent 1 si les valeurs sont différentes et 0 si elles sont identiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b2e33-87af-4d27-8f90-9d55ebabfd80",
   "metadata": {},
   "source": [
    "Cette fonctionalité existe dans `pandas` comme dans `scikit-learn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00392777-57d5-46d2-b37e-b4bb4ce0d2c6",
   "metadata": {},
   "source": [
    "### Transformation one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ad4f3-479d-441a-a9a8-2b1a73622709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouveau data frame où la colomne 'origin' est remplacée par son encodage 'one-hot'\n",
    "df_dummies = pd.get_dummies(df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec052382-d165-4482-a6a2-713b67a4da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a906004-5f54-410b-86a8-34d58a253608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire de nouveau les données\n",
    "X_dummies = np.array(df_dummies.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précédemment, on normalise chacune des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler_dummies = preprocessing.StandardScaler()\n",
    "standard_scaler_dummies.fit(X_dummies)\n",
    "X_scaled_dummies = standard_scaler_dummies.transform(X_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103380-0b5c-4dc8-8ca3-18982e2fa998",
   "metadata": {},
   "source": [
    "### Impact sur le modèle\n",
    "\n",
    "Nous allons maintenant apprendre une régression linéaire sur les données où la variable `origin` a été remplacée par son encodage one-hot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362a967-8b18-4264-8f54-6f04358fc43f",
   "metadata": {},
   "source": [
    "Pour cela, nous créons une instance `predictor_dummy` de la classe `LinearRegression` entraînée sur les données contenant la version _one-hot_ de la variable `origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688290ac-c9b9-4230-96f5-f72c7235d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouvel objet LinearRegression \n",
    "predictor_dummy = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_dummy sur les nouvelles données\n",
    "predictor_dummy.fit(X_scaled_dummies, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc077964-19ac-4f15-ab78-f9db2dca8168",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant créer un array `y_pred_dummy` qui contient les prédictions de la nouvelle régression linéaire sur les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1090d-a950-4a2b-ac6e-ebeb0833549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = predictor_dummy.predict(X_scaled_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90abfd80-19ec-4812-82f2-f834ad5a298a",
   "metadata": {},
   "source": [
    "La RMSE de ce nouveau modèle est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2c6ea-3ad1-4cea-90cf-2cc53d4bb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE (encodage one-hot): %.2f\" % metrics.mean_squared_error(y, y_pred_dummy, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d11270-1c07-4148-871f-1f39c961a108",
   "metadata": {},
   "source": [
    "__Question :__ La comparer à la RMSE précédente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3520af-b937-4cf2-97aa-e41fdab0eddc",
   "metadata": {},
   "source": [
    "#### Comparaison aux prédictions précédentes\n",
    "\n",
    "Les performances sont-elles vraiment différentes ? Nous pouvons comparer les prédictions directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ac203-b8f4-4f13-a293-c3dc9b129291",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred, y_pred_dummy)\n",
    "\n",
    "plt.xlabel(\"Consommation prédite (mpg) (baseline)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg) (avec one-hot)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_pred), np.min(y_pred_dummy)])-1\n",
    "axis_max = np.max([np.max(y_pred), np.max(y_pred_dummy)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08024f4f-4997-4d33-9901-78a228f5706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53b69e-d9db-4a14-9de8-98e73522d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, pval = st.pearsonr(y_pred, y_pred_dummy)\n",
    "print(\"Corrélation entre les prédictions : %.2f (p=%.2e)\" % (r, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61ca29-96ef-4c48-bce0-dfad7c12678d",
   "metadata": {},
   "source": [
    "#### Comparaison des coefficients de régression\n",
    "\n",
    "Comparons maintenant les deux modèles visuellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28983c-9a70-4b1a-924b-70cb185a42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour chaque variable, la valeur absolue de son coefficient dans le modèle\n",
    "num_features = X.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor_scaled.coef_), label='Centrées-réduites')\n",
    "\n",
    "num_features2 = X_scaled_dummies.shape[1]\n",
    "plt.scatter(range(num_features2), np.abs(predictor_dummy.coef_), label='Avec one-hot', marker='v')\n",
    "feature_names2 = df_dummies.drop(columns=['mpg', 'car name']).columns\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features2), feature_names2, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.75))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
